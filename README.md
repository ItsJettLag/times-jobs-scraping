# Job Listings Data Analysis | May 2024 - June 2024

This project involved scraping job listings, engineering an ETL pipeline, performing SQL analysis, and creating an interactive dashboard to visualize the job market insights.

## Overview
- **Data Source**: Times Now Jobs
- **Technologies**: Python, Beautiful Soup, Selenium, Apache Airflow, PostgreSQL, Power BI
- **Tools**: Power BI, PostgreSQL, Airflow

## Project Breakdown

### 1. Scraping Job Listings
- Scraped 1,000 job listings using Python, Beautiful Soup, and Selenium.
- Extracted key fields such as job title, company, location, skills required, and experience level.

### 2. ETL Pipeline
- Engineered an ETL (Extract, Transform, Load) pipeline using Python and Apache Airflow.
- Cleaned and transformed the scraped data (handling missing values, standardizing formats).
- Loaded the cleaned data into PostgreSQL tables for further analysis.

### 3. SQL Analysis
- Conducted SQL queries to derive insights, including:
  - **Top cities** with the most job opportunities.
  - **In-demand skills** and technologies.
  - **Entry-level job roles** for freshers.
  - Other key job market metrics.

### 4. Data Visualization
- Created an interactive **Power BI dashboard** to visualize key insights:
  - Job distribution by city, experience level, and industry.
  - Trend analysis for job postings over time.
  - Visualization of the most valued skills in the market.

## Results
- Enabled data-driven insights for job seekers and recruiters.
- Highlighted the skills and locations with the highest demand.

## How to Run
-Only code has been displayed here. The rest should be DIY based on the steps mentioned above
